{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful code\n",
    "https://www.kaggle.com/papadopc/sf-crime/neural-nets-and-address-featurization/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train_data = pd.read_csv('train.csv', parse_dates =['Dates'], dtype='object', index_col=False)\n",
    "test_data = pd.read_csv('test.csv', parse_dates =['Dates'], dtype='object', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425891675136</td>\n",
       "      <td>37.7745985956747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425891675136</td>\n",
       "      <td>37.7745985956747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                  Descript  DayOfWeek  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
       "\n",
       "  PdDistrict      Resolution             Address                  X  \\\n",
       "0   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST  -122.425891675136   \n",
       "1   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST  -122.425891675136   \n",
       "\n",
       "                  Y  \n",
       "0  37.7745985956747  \n",
       "1  37.7745985956747  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.39958770418998</td>\n",
       "      <td>37.7350510103906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391522893042</td>\n",
       "      <td>37.7324323864471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dates DayOfWeek PdDistrict                  Address  \\\n",
       "Id                                                                     \n",
       "0  2015-05-10 23:59:00    Sunday    BAYVIEW  2000 Block of THOMAS AV   \n",
       "1  2015-05-10 23:51:00    Sunday    BAYVIEW       3RD ST / REVERE AV   \n",
       "\n",
       "                      X                 Y  \n",
       "Id                                         \n",
       "0   -122.39958770418998  37.7350510103906  \n",
       "1     -122.391522893042  37.7324323864471  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARCENY/THEFT                  174900\n",
       "OTHER OFFENSES                 126182\n",
       "NON-CRIMINAL                    92304\n",
       "ASSAULT                         76876\n",
       "DRUG/NARCOTIC                   53971\n",
       "VEHICLE THEFT                   53781\n",
       "VANDALISM                       44725\n",
       "WARRANTS                        42214\n",
       "BURGLARY                        36755\n",
       "SUSPICIOUS OCC                  31414\n",
       "MISSING PERSON                  25989\n",
       "ROBBERY                         23000\n",
       "FRAUD                           16679\n",
       "FORGERY/COUNTERFEITING          10609\n",
       "SECONDARY CODES                  9985\n",
       "WEAPON LAWS                      8555\n",
       "PROSTITUTION                     7484\n",
       "TRESPASS                         7326\n",
       "STOLEN PROPERTY                  4540\n",
       "SEX OFFENSES FORCIBLE            4388\n",
       "DISORDERLY CONDUCT               4320\n",
       "DRUNKENNESS                      4280\n",
       "RECOVERED VEHICLE                3138\n",
       "KIDNAPPING                       2341\n",
       "DRIVING UNDER THE INFLUENCE      2268\n",
       "RUNAWAY                          1946\n",
       "LIQUOR LAWS                      1903\n",
       "ARSON                            1513\n",
       "LOITERING                        1225\n",
       "EMBEZZLEMENT                     1166\n",
       "SUICIDE                           508\n",
       "FAMILY OFFENSES                   491\n",
       "BAD CHECKS                        406\n",
       "BRIBERY                           289\n",
       "EXTORTION                         256\n",
       "SEX OFFENSES NON FORCIBLE         148\n",
       "GAMBLING                          146\n",
       "PORNOGRAPHY/OBSCENE MAT            22\n",
       "TREA                                6\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_data[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARCENY/THEFT                  174900\n",
       "OTHER OFFENSES                 126182\n",
       "NON-CRIMINAL                    92304\n",
       "ASSAULT                         76876\n",
       "DRUG/NARCOTIC                   53971\n",
       "VEHICLE THEFT                   53781\n",
       "VANDALISM                       44725\n",
       "WARRANTS                        42214\n",
       "BURGLARY                        36755\n",
       "SUSPICIOUS OCC                  31414\n",
       "MISSING PERSON                  25989\n",
       "ROBBERY                         23000\n",
       "FRAUD                           16679\n",
       "FORGERY/COUNTERFEITING          10609\n",
       "SECONDARY CODES                  9985\n",
       "WEAPON LAWS                      8555\n",
       "PROSTITUTION                     7484\n",
       "TRESPASS                         7326\n",
       "STOLEN PROPERTY                  4540\n",
       "SEX OFFENSES FORCIBLE            4388\n",
       "DISORDERLY CONDUCT               4320\n",
       "DRUNKENNESS                      4280\n",
       "RECOVERED VEHICLE                3138\n",
       "KIDNAPPING                       2341\n",
       "EMBEZZLEMENT                     2332\n",
       "DRIVING UNDER THE INFLUENCE      2268\n",
       "RUNAWAY                          1946\n",
       "LIQUOR LAWS                      1903\n",
       "ARSON                            1513\n",
       "LOITERING                        1225\n",
       "SUICIDE                          1016\n",
       "FAMILY OFFENSES                   982\n",
       "BAD CHECKS                        812\n",
       "BRIBERY                           578\n",
       "EXTORTION                         512\n",
       "SEX OFFENSES NON FORCIBLE         444\n",
       "GAMBLING                          438\n",
       "PORNOGRAPHY/OBSCENE MAT           110\n",
       "TREA                              102\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = train_data[train_data.Category == \"TREA\"]\n",
    "df2 = train_data[train_data.Category == \"PORNOGRAPHY/OBSCENE MAT\"]\n",
    "df3 = train_data[train_data.Category == \"GAMBLING\"]\n",
    "df4 = train_data[train_data.Category == \"SEX OFFENSES NON FORCIBLE\"]\n",
    "df5 = train_data[train_data.Category == \"EXTORTION\"]\n",
    "df6 = train_data[train_data.Category == \"BRIBERY\"]\n",
    "df7 = train_data[train_data.Category == \"BAD CHECKS\"]\n",
    "df8 = train_data[train_data.Category == \"FAMILY OFFENSES\"]\n",
    "df9 = train_data[train_data.Category == \"SUICIDE\"]\n",
    "df10 = train_data[train_data.Category == \"EMBEZZLEMENT\"]\n",
    "\n",
    "train_data = pd.concat([train_data, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, df1, \n",
    "                        df2, df2, df2, df2,\n",
    "                        df3, df3,\n",
    "                        df4, df4,\n",
    "                        df5,df6,df7,df8,df9,df10])\n",
    "\n",
    "pd.value_counts(train_data[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates         881937\n",
      "Category      881937\n",
      "Descript      881937\n",
      "DayOfWeek     881937\n",
      "PdDistrict    881937\n",
      "Resolution    881937\n",
      "Address       881937\n",
      "X             881937\n",
      "Y             881937\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = train_data\n",
    "print(train_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('categories:', 39, '\\npdDistricts:', 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dates         datetime64[ns]\n",
       "Category             float64\n",
       "Descript              object\n",
       "DayOfWeek            float64\n",
       "PdDistrict           float64\n",
       "Resolution            object\n",
       "Address               object\n",
       "X                    float64\n",
       "Y                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.unique(data['Category'])\n",
    "daysOfWeek = pd.unique(data['DayOfWeek'])\n",
    "pdDistricts = pd.unique(data['PdDistrict'])\n",
    "\n",
    "print(\"categories:\", len(categories), \"\\npdDistricts:\", len(pdDistricts))\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    data.loc[data[\"Category\"] == categories[i], \"Category\"] = i\n",
    "data[\"Category\"] = data[\"Category\"].astype(float)\n",
    "for i in range(len(daysOfWeek)):\n",
    "    data.loc[data[\"DayOfWeek\"] == daysOfWeek[i], \"DayOfWeek\"] = i\n",
    "data[\"DayOfWeek\"] = data[\"DayOfWeek\"].astype(float)\n",
    "for i in range(len(pdDistricts)):\n",
    "    data.loc[data[\"PdDistrict\"] == pdDistricts[i], \"PdDistrict\"] = i\n",
    "data[\"PdDistrict\"] = data[\"PdDistrict\"].astype(float)\n",
    "\n",
    "data[\"X\"] = data[\"X\"].astype(float)\n",
    "data[\"Y\"] = data[\"Y\"].astype(float)\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Category</th>\n",
       "      <th>PdDistrict_0.0</th>\n",
       "      <th>PdDistrict_1.0</th>\n",
       "      <th>PdDistrict_2.0</th>\n",
       "      <th>PdDistrict_3.0</th>\n",
       "      <th>PdDistrict_4.0</th>\n",
       "      <th>PdDistrict_5.0</th>\n",
       "      <th>PdDistrict_6.0</th>\n",
       "      <th>PdDistrict_7.0</th>\n",
       "      <th>PdDistrict_8.0</th>\n",
       "      <th>PdDistrict_9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  Category  PdDistrict_0.0  PdDistrict_1.0  PdDistrict_2.0  \\\n",
       "0          0         0               1               0               0   \n",
       "1          0         1               1               0               0   \n",
       "\n",
       "   PdDistrict_3.0  PdDistrict_4.0  PdDistrict_5.0  PdDistrict_6.0  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "\n",
       "   PdDistrict_7.0  PdDistrict_8.0  PdDistrict_9.0  \n",
       "0               0               0               0  \n",
       "1               0               0               0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make PdDistrict a dummy variable\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data[[\"DayOfWeek\",\"PdDistrict\", \"Category\"]], columns=[\"PdDistrict\"])\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('all', 2.6562574657211377)\n",
      "('train', 2.6238775773445102)\n",
      "('test', 2.6664874471311735)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "predictors = [\"DayOfWeek\", 'PdDistrict_0.0', 'PdDistrict_1.0', 'PdDistrict_2.0', 'PdDistrict_3.0', 'PdDistrict_4.0',\n",
    "              'PdDistrict_5.0', 'PdDistrict_6.0', 'PdDistrict_7.0', 'PdDistrict_8.0', 'PdDistrict_9.0']\n",
    "\n",
    "features, labels = df[predictors], df[\"Category\"]\n",
    "features.index=range(len(features))\n",
    "labels.index=range(len(labels))\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=9, max_depth=None, min_samples_split=1, random_state=0)\n",
    "sss = StratifiedShuffleSplit(labels, n_iter=5, test_size=0.2, train_size=0.2, random_state=42)\n",
    "   \n",
    "for train_index, test_index in sss:\n",
    "    features_train,features_test=features.iloc[train_index],features.iloc[test_index]\n",
    "    labels_train,labels_test=labels[train_index],labels[test_index]\n",
    "features_test.index=range(len(features_test))\n",
    "features_train.index=range(len(features_train))\n",
    "labels_train.index=range(len(labels_train))\n",
    "labels_test.index=range(len(labels_test))\n",
    "features.index=range(len(features))\n",
    "labels.index=range(len(labels))\n",
    "\n",
    "#model = LogisticRegression()\n",
    "model = ExtraTreesClassifier(n_estimators=9, max_depth=None, min_samples_split=1, random_state=0)\n",
    "model.fit(features_train,labels_train)\n",
    "\n",
    "print(\"all\", log_loss(labels, model.predict_proba(features.as_matrix())))\n",
    "print(\"train\", log_loss(labels_train, model.predict_proba(features_train.as_matrix())))\n",
    "print(\"test\", log_loss(labels_test, model.predict_proba(features_test.as_matrix())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-a50017266649>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-a50017266649>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    sss1 = StratifiedShuffleSplit(y_80[y_train], n_iter=2, train_size=0.2, test_size=0.2 random_state=42)\u001b[0m\n\u001b[0m                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "districts_columns=df.columns[8:]\n",
    "predictors = districts_columns.append(\"DayOfWeek\")\n",
    "\n",
    "X, y = df[predictors], df[\"Category\"]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 4 classifieres:\n",
    "clf1 = RandomForestClassifier(n_estimators=25)\n",
    "clf2 = RandomForestClassifier(n_estimators=25)\n",
    "clf3 = RandomForestClassifier(n_estimators=25)\n",
    "clf4 = RandomForestClassifier(n_estimators=25)\n",
    "clfs = [clf1, clf2, clf3, clf4, clf5]\n",
    "\n",
    "sss = StratifiedShuffleSplit(y, n_iter=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_80, X_20 = X[train_index], X[test_index]\n",
    "    y_80, y_20 = y[train_index], y[test_index]\n",
    "    \n",
    "    for clf_i in clfs:\n",
    "        sss1 = StratifiedShuffleSplit(y_80[y_train], n_iter=2, train_size=0.2, test_size=0.2 random_state=42)\n",
    "        for train_index1, test_index1 in sss1:\n",
    "            clf_i.fit(X_80[train_index1], y_80[train_index1])\n",
    "            clf_probs = clf_i.predict_proba(X_80[test_index1])\n",
    "            score = log_loss(y_80[test_index1], clf_probs)\n",
    "    \n",
    "    # need to make bagging of clfs\n",
    "    # clfs = ...\n",
    "\n",
    "\n",
    "    clfs.fit(X_train, y_train)\n",
    "    clfs_probs = clfs.predict_proba(X_20)\n",
    "    \n",
    "    sig_clf = CalibratedClassifierCV(clfs, method=\"sigmoid\", cv=\"prefit\")\n",
    "    \n",
    "    sig_clf.fit(X_valid, y_valid)\n",
    "    sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "    sig_score = log_loss(y_test, sig_clf_probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here I was trying to make SVM + grid search\n",
    "\n",
    "districts_columns=df.columns[8:]\n",
    "predictors = [\"DayOfWeek\",'PdDistrict_1.0', 'PdDistrict_2.0', 'PdDistrict_3.0', 'PdDistrict_4.0', 'PdDistrict_5.0',\n",
    "              'PdDistrict_6.0', 'PdDistrict_7.0', 'PdDistrict_8.0', 'PdDistrict_9.0']\n",
    "\n",
    "X, y = df[predictors], df[\"Category\"]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(y, n_iter=2, test_size=0.05, train_size=0.2, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of classes 31, 35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-748cb51905e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train random forest classifier, calibrate on validation data and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         raise ValueError(\"y_true and y_pred have different number of classes \"\n\u001b[0;32m-> 1565\u001b[0;31m                          \"%d, %d\" % (T.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0;31m# Renormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different number of classes 31, 35"
     ]
    }
   ],
   "source": [
    "# Train uncalibrated random forest classifier on whole train and validation\n",
    "# data and evaluate on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train_valid, y_train_valid)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "score = log_loss(y_test, clf_probs)\n",
    "\n",
    "\n",
    "# Train random forest classifier, calibrate on validation data and evaluate\n",
    "# on test data\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(X_valid, y_valid)\n",
    "sig_clf_probs = sig_clf.predict_proba(X_test)\n",
    "sig_score = log_loss(y_test, sig_clf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, X, y, cv=6)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "clf2 = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "\n",
    "scores = cross_validation.cross_val_score(clf2, X, y, cv=6)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\n",
    "accuracy = sum([1 if predictions[i]==data[\"Category\"][i] else 0 for i in range(len(predictions))]) / len(data[\"Category\"])\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For submission\n",
    "\n",
    "# Initialize the algorithm class\n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
